{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bids(n, m, p_bar):\n",
    "    \"\"\"\n",
    "    Generate a sequence of random bids.\n",
    "    :param n: Total number of bids.\n",
    "    :param m: Number of items.\n",
    "    :param p_bar: Ground truth price vector.\n",
    "    :return: Array of bids.\n",
    "    \"\"\"\n",
    "    bids = []\n",
    "    for _ in range(n):\n",
    "        a_k = np.random.choice([0, 1], size=m)  # Generate a_k\n",
    "        pi_k = np.dot(p_bar, a_k) + np.random.normal(0, np.sqrt(0.2))  # Calculate bid price\n",
    "        bids.append((a_k, pi_k))\n",
    "    return bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_partial_lp_dual(bids, k, n, m, b_i):\n",
    "    \"\"\"\n",
    "    Solve the partial linear program (SLPM) for the first k bids and extract the dual prices.\n",
    "    :param bids: Sequence of bids.\n",
    "    :param k: Number of bids to consider in the LP.\n",
    "    :param n: Total number of bids.\n",
    "    :param m: Number of items.\n",
    "    :param b_i: Capacity for each item.\n",
    "    :return: Dual prices (y_bar).\n",
    "    \"\"\"\n",
    "    # Objective function: maximize sum(pi_j * x_j) for j=1 to k\n",
    "    c = -np.array([pi_k for _, pi_k in bids[:k]])\n",
    "\n",
    "    # Constraints: sum(a_ij * x_j) <= (k/n) * b_i for all i\n",
    "    A = np.array([a_k for a_k, _ in bids[:k]]).T # shape: (m, k)\n",
    "    b = (k / n) * np.array(b_i)\n",
    "    \n",
    "    # Bounds for decision variables: 0 <= x_j <= 1\n",
    "    x_bounds = [(0, 1) for _ in range(k)]\n",
    "\n",
    "    # Solve the linear program\n",
    "    result = linprog(c, A_ub=A, b_ub=b, bounds=x_bounds, method='highs')\n",
    "\n",
    "    if result.success:\n",
    "        # The dual variable corresponding to the inequality constraints A_ub * x <= b_ub\n",
    "        return result.get('slack')\n",
    "    else:\n",
    "        raise ValueError(\"Linear programming failed to find a solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_slpm(bids, k, n, m, b_i):\n",
    "    \"\"\"\n",
    "    Run the revised SLPM algorithm.\n",
    "    :param bids: Sequence of bids.\n",
    "    :param k: Size of k for the SLPM algorithm.\n",
    "    :param n: Total number of bids.\n",
    "    :param m: Number of items.\n",
    "    :param b_i: Capacity for each item.\n",
    "    :return: Total revenue generated.\n",
    "    \"\"\"\n",
    "    revenue = 0\n",
    "    remaining_capacity = np.array(b_i)\n",
    "    \n",
    "    # Solve the partial LP for the first k bids to get dual prices\n",
    "    y_bar = solve_partial_lp_dual(bids, k, n, m, b_i)\n",
    "\n",
    "    # Adjust capacity for each item based on the dual prices\n",
    "    b_i -= y_bar\n",
    "\n",
    "\n",
    "    for i, (a_k, pi_k) in enumerate(bids):\n",
    "        if i >= k:\n",
    "            # Allocate based on the decision rule using y_bar\n",
    "            if pi_k > np.dot(a_k, y_bar) and all(remaining_capacity - a_k >= 0):\n",
    "                revenue += pi_k\n",
    "                remaining_capacity -= a_k\n",
    "\n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_offline_lp(bids, m, b_i):\n",
    "    \"\"\"\n",
    "    Solve the offline linear programming problem.\n",
    "    :param bids: Sequence of all bids.\n",
    "    :param m: Number of items.\n",
    "    :param b_i: Resource limit for all i.\n",
    "    :return: Total revenue from the offline LP solution.\n",
    "    \"\"\"\n",
    "    c = -np.array([pi_k for _, pi_k in bids])  # Negative for maximization\n",
    "    A = np.array([a_k for a_k, _ in bids]).T  # Transpose to match dimensions\n",
    "    b = b_i * np.ones(m)    \n",
    "\n",
    "    # Solving the LP\n",
    "    result = linprog(c, A_ub=A, b_ub=b, bounds=(0, 1), method='highs')\n",
    "\n",
    "    if result.success:\n",
    "        return -result.fun  # Revenue (negate because of maximization)\n",
    "    else:\n",
    "        raise ValueError(\"Offline LP did not converge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLPM revenue: 10005.45842518648 at k=50\n",
      "SLPM revenue: 10006.250098949256 at k=100\n",
      "SLPM revenue: 10009.94451409099 at k=200\n",
      "Offline revenue: 11326.588623160282\n"
     ]
    }
   ],
   "source": [
    "def run_simulation(n, m, p_bar, k_values):\n",
    "    # Regenerate bids with the fixed p_bar\n",
    "    bids_fixed = generate_bids(n, m, p_bar)\n",
    "\n",
    "    b_i = np.ones(m) * 1000  # Bid cap for all i\n",
    "\n",
    "    slpm_revenues = {k: run_slpm(bids_fixed, k, n, m, b_i) for k in k_values}\n",
    "\n",
    "    for slpm_revenue, k in zip(slpm_revenues.values(), k_values):\n",
    "        print(f\"SLPM revenue: {slpm_revenue} at k={k}\")\n",
    "\n",
    "    offline_revenue_value = solve_offline_lp(bids_fixed, m, b_i)\n",
    "\n",
    "    print(f\"Offline revenue: {offline_revenue_value}\")\n",
    "\n",
    "# Simulation parameters\n",
    "n = 10000  # Total number of bids\n",
    "m = 10     # Number of items\n",
    "k_values = [50, 100, 200]  # Different k values to test\n",
    "\n",
    "# Fixed ground truth price vector (p_bar) - set to ones for simplicity\n",
    "p_bar_fixed = np.ones(m)  # Vector of ones\n",
    "\n",
    "run_simulation(n, m, p_bar_fixed, k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade-off between high and low k\n",
    "\n",
    "Choosing a Large $k$ :\n",
    "1. Stability and Accuracy:\n",
    "- A larger $k$ means that the algorithm considers a greater number of past bids before making a decision. This can lead to more stable and potentially more accurate estimations of the optimal pricing or decision-making strategy because it relies on a more comprehensive set of historical data.\n",
    "- The decisions are less likely to be influenced by short-term fluctuations or anomalies in the bid data, which might be beneficial in environments where the underlying distribution of bids doesn't change rapidly.\n",
    "2. Reduced Responsiveness:\n",
    "- The downside is that the algorithm becomes less responsive to recent trends or changes in the bidding environment. If the nature of the bids changes suddenly, it might take longer for these changes to be reflected in the decision-making process.\n",
    "- In fast-changing markets or scenarios where recent data is significantly more relevant than older data, a larger $k$ might lead to suboptimal decisions.\n",
    "\n",
    "Choosing a Small $k$ :\n",
    "1. Responsiveness to New Information:\n",
    "- A smaller $k$ makes the algorithm more responsive to recent bids. This can be advantageous in dynamic environments where the characteristics of bids change frequently, and staying up-to-date with the most recent trends is crucial.\n",
    "- It allows the algorithm to quickly adapt to new information, potentially capturing opportunities that a more stable, slower-to-adapt approach might miss.\n",
    "2. Potential Instability and Inaccuracy:\n",
    "- The drawback is that with fewer data points considered, the estimations and decisions might be less stable and less accurate. The algorithm is more susceptible to being influenced by outliers or short-term fluctuations in the bid data.\n",
    "- Decisions might be over-fitted to recent but possibly non-representative data, leading to erratic or suboptimal bidding strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_slpm_revised(bids, k_values, n, m, b_i):\n",
    "    \"\"\"\n",
    "    Run the revised SLPM algorithm with dynamic dual price updates.\n",
    "    :param bids: Sequence of bids.\n",
    "    :param k_values: Points at which to update the dual prices.\n",
    "    :param n: Total number of bids.\n",
    "    :param m: Number of items.\n",
    "    :param b_i: Capacity for each item.\n",
    "    :return: Total revenue generated.\n",
    "    \"\"\"\n",
    "    revenue = 0\n",
    "    remaining_capacity = np.array(b_i)\n",
    "    y_bar = None\n",
    "\n",
    "    for i, (a_k, pi_k) in enumerate(bids):\n",
    "        # Update dual prices at specified points\n",
    "        if i in k_values or i == 0:\n",
    "            y_bar = solve_partial_lp_dual(bids, i + 1, n, m, remaining_capacity)\n",
    "\n",
    "        # Allocate based on the decision rule using y_bar\n",
    "        if y_bar is not None and pi_k > np.dot(a_k, y_bar) and all(remaining_capacity - a_k >= 0):\n",
    "            revenue += pi_k\n",
    "            remaining_capacity -= a_k\n",
    "\n",
    "    return revenue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLPM revenue: 9969.348547850243 at k=50\n",
      "SLPM revenue: 9977.23567103672 at k=100\n",
      "SLPM revenue: 9990.886998024376 at k=200\n",
      "Offline revenue: 11336.211826909263\n"
     ]
    }
   ],
   "source": [
    "def run_simulation_problem_2(n, m, p_bar, k_values):\n",
    "    # Regenerate bids with the fixed p_bar\n",
    "    bids_fixed = generate_bids(n, m, p_bar)\n",
    "\n",
    "\n",
    "    b_i = np.ones(m) * 1000  # Bid cap for all i\n",
    "\n",
    "    slpm_revenues_revised = {k: run_slpm_revised(bids_fixed, k, n, m, b_i) for k in k_values}\n",
    "\n",
    "    for slpm_revenue, k in zip(slpm_revenues_revised.values(), k_values):\n",
    "        print(f\"SLPM revenue: {slpm_revenue} at k={k}\")\n",
    "\n",
    "    offline_revenue_value = solve_offline_lp(bids_fixed, m, b_i)\n",
    "\n",
    "    print(f\"Offline revenue: {offline_revenue_value}\")\n",
    "\n",
    "# Simulation parameters\n",
    "n = 10000  # Total number of bids\n",
    "m = 10     # Number of items\n",
    "k_values = [50, 100, 200]  # Different k values to test\n",
    "\n",
    "# Fixed ground truth price vector (p_bar) - set to ones for simplicity\n",
    "p_bar_fixed = np.ones(m)  # Vector of ones\n",
    "\n",
    "run_simulation(n, m, p_bar_fixed, k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8657512983475957,\n",
       " 5.79783055695639,\n",
       " 7.534832765856239,\n",
       " 9.847318988128336,\n",
       " 13.459262929498934,\n",
       " 20.307540281444936,\n",
       " 23.060936512134887,\n",
       " 25.209605502991117,\n",
       " 29.227883312537333,\n",
       " 35.27814051432472]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ahlda(bids, k, n, m, b_i, opt):\n",
    "    \"\"\"\n",
    "    Action-history-dependent Learning Algorithm.\n",
    "    \"\"\"\n",
    "    revenue = 0\n",
    "    remaining_capacity = np.array(b_i)\n",
    "    performance = []\n",
    "\n",
    "    for i in range(1, k + 1):\n",
    "        # Update dual prices\n",
    "        y_bar = solve_partial_lp_dual(bids, i, n, m, remaining_capacity)\n",
    "\n",
    "        # Make decision for bid i\n",
    "        a_k, pi_k = bids[i - 1]\n",
    "        if pi_k > np.dot(a_k, y_bar) and all(remaining_capacity - a_k >= 0):\n",
    "            revenue += pi_k\n",
    "            remaining_capacity -= a_k\n",
    "        \n",
    "        # Compute performance metric\n",
    "        performance.append(revenue - (i / n) * opt)\n",
    "\n",
    "    return performance\n",
    "\n",
    "# Parameters\n",
    "n = 10000\n",
    "m = 10\n",
    "p_bar_fixed = np.ones(m)\n",
    "b_i = np.ones(m) * 1000\n",
    "k_values = [50, 100, 200]\n",
    "\n",
    "# Generate bids\n",
    "bids = generate_bids(n, m, p_bar_fixed)\n",
    "\n",
    "# Solve offline problem for OPT\n",
    "opt = solve_offline_lp(bids, m, b_i)\n",
    "\n",
    "# AHDLA algorithm performance\n",
    "ahlda_performance = {k: ahlda(bids, k, n, m, b_i, opt) for k in k_values}\n",
    "\n",
    "ahlda_performance[200][:10]  # Display first 10 performance metrics for k=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.996176485466778,\n",
       " 6.928255744075572,\n",
       " 8.665257952975422,\n",
       " 10.977744175247519,\n",
       " 14.589688116618117,\n",
       " 21.43796546856412,\n",
       " 24.19136169925407,\n",
       " 26.340030690110297,\n",
       " 30.358308499656516,\n",
       " 36.408565701443905]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def performance_metric_slpm_revised(bids, k_values, n, m, b_i, opt):\n",
    "    \"\"\"\n",
    "    Run the revised SLPM algorithm with dynamic dual price updates and compute performance metrics.\n",
    "    \"\"\"\n",
    "    performance = {}\n",
    "    for k in k_values:\n",
    "        revenue = 0\n",
    "        remaining_capacity = np.array(b_i)\n",
    "        y_bar = None\n",
    "        performance_k = []\n",
    "\n",
    "        for i, (a_k, pi_k) in enumerate(bids):\n",
    "            if i >= k:  # Only consider bids after k\n",
    "                break\n",
    "\n",
    "            # Update dual prices at specified points or at the start\n",
    "            if i in k_values or i == 0:\n",
    "                y_bar = solve_partial_lp_dual(bids, i + 1, n, m, remaining_capacity)\n",
    "\n",
    "            # Allocate based on the decision rule using y_bar\n",
    "            if y_bar is not None and pi_k > np.dot(a_k, y_bar) and all(remaining_capacity - a_k >= 0):\n",
    "                revenue += pi_k\n",
    "                remaining_capacity -= a_k\n",
    "\n",
    "            # Compute performance metric\n",
    "            performance_k.append(revenue - (i / n) * opt)\n",
    "\n",
    "        performance[k] = performance_k\n",
    "\n",
    "    return performance\n",
    "\n",
    "# SLPM algorithm performance\n",
    "slpm_performance = performance_metric_slpm_revised(bids, k_values, n, m, b_i, opt)\n",
    "\n",
    "# Display the first 10 performance metrics for k=200 from SLPM\n",
    "slpm_performance[200][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between AHDLA and SLPM\n",
    "- Initial Performance: Both algorithms show a growing trend in performance as more bids are considered. This is expected as accumulating more accepted bids typically increases total revenue.\n",
    "- Performance Metrics: The performance metrics of both algorithms are quite similar, especially in the later stages (e.g., at bid 10). This suggests that both algorithms are effectively capturing the value of bids over time relative to the optimal offline solution.\n",
    "- Algorithmic Differences: The key difference lies in how AHDLA dynamically updates decision-making based on action history, while SLPM focuses more on a static decision rule informed by a subset of bids. AHDLA's approach could potentially be more responsive to variations in bid quality over time.\n",
    "\n",
    "From this analysis, it appears that both algorithms perform well, with neither showing a definitive advantage over the other based on these metrics. The choice between them may depend on specific characteristics of the bidding environment or computational constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convexity of (3)\n",
    "\n",
    "Problem 3 is given as:\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\operatorname{minimize}_{\\overline{\\mathbf{y}}} & \\mathbf{d}^T \\overline{\\mathbf{y}}+\\mathbb{E}\\left(\\pi-\\mathbf{a}^T \\overline{\\mathbf{y}}\\right)^{+} \\\\\n",
    "\\text {s.t. } & \\overline{\\mathbf{y}} \\geq 0\n",
    "\\end{array}\n",
    "$$\n",
    "where $\\mathbf{d}=\\mathbf{b} / n$ and $(\\cdot)^{+}=\\max \\{\\cdot, 0\\}$.\n",
    "\n",
    "The first term, $\\mathbf{d}^T \\overline{\\mathbf{y}}$, is linear in $\\overline{\\mathbf{y}}$. Linear functions are both convex and concave. The second term, $\\mathbb{E}\\left(\\pi-\\mathbf{a}^T \\overline{\\mathbf{y}}\\right)^{+}$, requires more consideration. The function $(\\cdot)^{+}$ is the positive part function, which is convex because it is the maximum of a linear function and zero (both convex functions). Therefore, $\\left(\\pi-\\mathbf{a}^T \\overline{\\mathbf{y}}\\right)^{+}$is convex in $\\overline{\\mathbf{y}}$ as it is the composition of a linear function and a convex function. The expectation operator $\\mathbb{E}$ preserves convexity. If a function $f(x)$ is convex, then $\\mathbb{E}[f(x)]$ is also convex. Therefore, $\\mathbb{E}\\left(\\pi-\\mathbf{a}^T \\overline{\\mathbf{y}}\\right)^{+}$is convex in $\\overline{\\mathbf{y}}$. The constraint $\\overline{\\mathbf{y}} \\geq 0$ is linear and therefore convex.\n",
    "\n",
    "\n",
    "Since both terms in the objective function are convex and the constraints are also convex (linear, in fact), the problem as a whole is a convex optimization problem. Convex problems have the desirable property that any local minimum is also a global minimum, making them easier to solve reliably and efficiently.\n",
    "\n",
    "Because the problem is convex, we know it can be solved efficiently and the solution is robust to things like initialization.\n",
    "\n",
    "## Connection to (1)\n",
    "In general, while Problem 1 is focused on a practical algorithmic approach to bid management in an online learning context, Problem 3 offers a theoretical counterpart that provides an optimal pricing strategy in a stochastic setting.\n",
    "\n",
    "\n",
    "In Problem 1, we had:\n",
    "\n",
    "- A one-time online learning algorithm, specifically the Sequential Linear Programming Method (SLPM), applied to a simulated bidding scenario.\n",
    "- The primary goal is to maximize revenue (or equivalently, minimize cost) through strategic bid acceptance, given a set of bids and resource constraints.\n",
    "- The algorithm is tested with different values of $ k $ (50, 100, 200), which influences how much of the bid data is considered in the decision-making process. This essentially determines the balance between responsiveness and stability in the pricing strategy.\n",
    "\n",
    "### Problem 3 Formulation:\n",
    "\n",
    "Problem 3 had:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize}_{\\overline{\\mathbf{y}}} & \\mathbf{d}^T \\overline{\\mathbf{y}} + \\mathbb{E}\\left(\\pi - \\mathbf{a}^T \\overline{\\mathbf{y}}\\right)^{+}, \\\\\n",
    "\\text{s.t.} & \\overline{\\mathbf{y}} \\geq 0,\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- Here, $\\mathbf{d}^T \\overline{\\mathbf{y}}$ represents a direct cost associated with the decision variables $\\overline{\\mathbf{y}}$, and $\\mathbb{E}\\left(\\pi - \\mathbf{a}^T \\overline{\\mathbf{y}}\\right)^{+}$ signifies the expected opportunity cost of not accepting certain bids.\n",
    "- The problem aims to find an optimal pricing strategy $\\overline{\\mathbf{y}}$ that minimizes the expected total cost, which includes both direct and opportunity costs.\n",
    "\n",
    "\n",
    "1. **Algorithmic Approach vs. Theoretical Optimization:**\n",
    "   - Problem 1 deals with an algorithmic approach to bid management, where decisions are made in an online setting based on limited information.\n",
    "   - Problem 3, on the other hand, represents a more theoretical approach to understanding the optimal pricing strategy in a stochastic environment. It's an optimization problem that considers the expected values of variables and costs.\n",
    "\n",
    "2. **Role of $ k $ and $\\overline{\\mathbf{y}}$:**\n",
    "   - In Problem 1, $ k $ determines how much historical bid data is used in setting the prices $\\overline{\\mathbf{y}}$. A larger $ k $ would mean more historical data influencing the pricing decision, potentially leading to a more stable but less responsive strategy.\n",
    "   - In Problem 3, $\\overline{\\mathbf{y}}$ is optimized considering the entire distribution of possible bids. This theoretical optimum could be seen as an ideal target for the online algorithm in Problem 1. The larger the $ k $, the closer the SLPM's decision-making process might come to this theoretical optimum.\n",
    "\n",
    "3. **Trade-offs in Decision Making:**\n",
    "   - Problem 1 highlights the trade-off between using more data for stability (large $ k $) and being more responsive to recent trends (small $ k $).\n",
    "   - Problem 3 implicitly addresses a similar trade-off by balancing direct costs and expected opportunity costs. The optimal solution $\\overline{\\mathbf{y}}$ in this problem is akin to finding a balance that minimizes total expected cost, considering both historical and potential future bids.\n",
    "\n",
    "4. **Stochastic Nature of Bidding:**\n",
    "   - Both problems acknowledge the uncertainty and stochastic nature of bidding. Problem 1 does this through the simulation of bids and online learning, while Problem 3 incorporates it through the expectation operator in its objective function.\n",
    "\n",
    "### Implications:\n",
    "\n",
    "- **SLPM as an Approximation to the Theoretical Optimum:** The SLPM algorithm can be viewed as an attempt to approximate the theoretically optimal pricing strategy (as conceptualized in Problem 3) in a real-time, dynamic environment.\n",
    "- **Insights from Problem 3 to Inform Problem 1:** The structure and solution of Problem 3 can provide valuable insights into how one might adjust the SLPM algorithm to better approach the optimal strategy, especially in how to balance historical data with responsiveness to new information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "To address Question 5, we'll develop a new online algorithm using Stochastic Gradient Descent (SGD) for the optimization problem stated in Problem 3. The aim is to update the dual price vectors $\\overline{\\mathbf{y}}$ more efficiently, especially when dealing with large-scale data.\n",
    "\n",
    "### SGD-Based Online Algorithm:\n",
    "\n",
    "The SGD approach updates the decision variables $\\overline{\\mathbf{y}}$ iteratively using an approximation of the gradient of the objective function. Given the derivative $ \\mathbf{f}(\\overline{\\mathbf{y}}) = \\mathbb{E}\\left(\\mathbf{d} - \\mathbf{a} \\mathbb{I}_{\\{\\pi > \\mathbf{a}^T \\overline{\\mathbf{y}}\\}}\\right) $, we can update $ \\overline{\\mathbf{y}} $ at each step based on the current bid's information.\n",
    "\n",
    "#### Algorithm Steps:\n",
    "\n",
    "1. **Initialization:**\n",
    "   - Set $ \\overline{\\mathbf{y}}^0 = 0 $ (initial dual price vector).\n",
    "\n",
    "2. **Iterative Update:**\n",
    "   - For each time step $ k $, update $ \\overline{\\mathbf{y}} $ using the formula:\n",
    "     $$\n",
    "     \\overline{\\mathbf{y}}^{k+1} = \\overline{\\mathbf{y}}^k - \\frac{1}{\\beta} \\mathbf{f}\\left(\\pi_k, \\mathbf{a}_k\\right)\n",
    "     $$\n",
    "   - Where $ \\beta = \\sqrt{k} $ and $ \\mathbf{f}\\left(\\pi_k, \\mathbf{a}_k\\right) = \\mathbf{d} - \\mathbf{a}_k \\mathbb{I}_{\\{\\pi_k > \\mathbf{a}_k^T \\overline{\\mathbf{y}}^k\\}} $.\n",
    "\n",
    "3. **Revenue Calculation:**\n",
    "   - At each step, calculate the revenue based on the current bid and the updated $ \\overline{\\mathbf{y}} $.\n",
    "\n",
    "4. **Convergence Check:**\n",
    "   - Monitor the convergence of $ \\overline{\\mathbf{y}} $ towards the true vector $ \\overline{\\mathbf{p}} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [array([-1.000e-04,  9.999e-01,  9.999e-01,  9.999e-01, -1.000e-04,\n",
       "         -1.000e-04,  9.999e-01,  9.999e-01, -1.000e-04,  9.999e-01]),\n",
       "  array([-1.70710678e-04,  1.70693607e+00,  1.70693607e+00,  1.70693607e+00,\n",
       "          7.06936071e-01,  7.06936071e-01,  9.99829289e-01,  1.70693607e+00,\n",
       "         -1.70710678e-04,  9.99829289e-01]),\n",
       "  array([0.57712182, 1.70687834, 1.70687834, 2.2842286 , 1.2842286 ,\n",
       "         0.70687834, 1.57712182, 2.2842286 , 0.57712182, 1.57712182]),\n",
       "  array([0.57707182, 1.70682834, 1.70682834, 2.2841786 , 1.2841786 ,\n",
       "         0.70682834, 1.57707182, 2.2841786 , 0.57707182, 1.57707182]),\n",
       "  array([0.5770271 , 1.70678361, 1.70678361, 2.28413388, 1.28413388,\n",
       "         0.70678361, 1.5770271 , 2.28413388, 0.5770271 , 1.5770271 ])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_gradient_descent(bids, m, d, beta_func, max_iter=10000):\n",
    "    \"\"\"\n",
    "    Implement the Stochastic Gradient Descent (SGD) algorithm for the online learning problem.\n",
    "    \"\"\"\n",
    "    y = np.zeros(m)  # Initialize y\n",
    "    revenue = 0\n",
    "    revenues = []\n",
    "    y_updates = []\n",
    "\n",
    "    for k in range(1, max_iter + 1):\n",
    "        a_k, pi_k = bids[k - 1]\n",
    "        beta = beta_func(k)\n",
    "\n",
    "        # Indicator function\n",
    "        indicator = 1 if pi_k > np.dot(a_k, y) else 0\n",
    "\n",
    "        # Gradient approximation\n",
    "        f = d - a_k * indicator\n",
    "\n",
    "        # Update y\n",
    "        y -= f / beta\n",
    "\n",
    "        # Calculate revenue\n",
    "        if pi_k > np.dot(a_k, y):\n",
    "            revenue += pi_k\n",
    "\n",
    "        # Store revenue and y updates for analysis\n",
    "        revenues.append(revenue)\n",
    "        y_updates.append(y.copy())\n",
    "\n",
    "    return revenues, y_updates\n",
    "\n",
    "# Simulation parameters\n",
    "m = 10  # Number of items\n",
    "d = np.ones(m) / 10000  # Vector d as b/n\n",
    "beta_func = lambda k: np.sqrt(k)  # Beta function\n",
    "\n",
    "# Run SGD algorithm\n",
    "sgd_revenues, sgd_y_updates = stochastic_gradient_descent(bids, m, d, beta_func)\n",
    "\n",
    "# Analyze the first few updates and revenues\n",
    "sgd_revenues[:10], sgd_y_updates[:5]  # Display first 10 revenues and first 5 y updates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue Performance:\n",
    "\n",
    "This sequence of revenues above indicates an initial increase, followed by a plateau. This pattern suggests that the algorithm quickly adapts to the bidding data, but then stabilizes in its decision-making.\n",
    "\n",
    "### Convergence of $ \\overline{\\mathbf{y}} $:\n",
    "\n",
    "The first five updates to the dual price vector $ \\overline{\\mathbf{y}} $ are shown. The updates show a trend of changes, reflecting the algorithm's responsiveness to the bid data. However, the convergence of these vectors towards the true vector $ \\overline{\\mathbf{p}} $ is not immediately evident from these early steps and would require a more detailed analysis over a larger number of iterations.\n",
    "\n",
    "### Observations and Findings:\n",
    "\n",
    "- **Dynamic Learning Performance:** The SGD-based algorithm demonstrates dynamic learning capabilities, adapting its pricing strategy based on the observed bids. The choice of $ \\beta = \\sqrt{k} $ appears to provide a balance between rapid adaptation and stability.\n",
    "- **Convergence Assessment:** To assess the convergence of $ \\overline{\\mathbf{y}} $ to $ \\overline{\\mathbf{p}} $, we would need to examine the trajectory of $ \\overline{\\mathbf{y}} $ updates over a longer period and possibly compare them to a known or estimated true price vector $ \\overline{\\mathbf{p}} $. The convergence may depend on various factors, including the nature of the bid data and the scaling factor $ \\beta $.\n",
    "- **Comparison with Previous Algorithms:** It's important to compare the SGD algorithm's performance with the earlier algorithms (SLPM and AHDLA) in terms of both revenue generation and computational efficiency. The SGD approach is expected to be more efficient, particularly for large $ n $, due to its iterative and gradient-based nature.\n",
    "\n",
    "In conclusion, the SGD-based online algorithm shows promise in terms of adaptability and efficiency, especially for large-scale problems. However, a comprehensive evaluation of its long-term performance and convergence properties is necessary to fully understand its effectiveness and potential advantages over traditional LP-based methods in online learning scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
