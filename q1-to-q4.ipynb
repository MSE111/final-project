{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "YDT4PPaNyGTp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def generate_bids(n, m, p_bar):\n",
        "    \"\"\"\n",
        "    Generate a sequence of random bids.\n",
        "    :param n: Total number of bids.\n",
        "    :param m: Number of items.\n",
        "    :param p_bar: Ground truth price vector.\n",
        "    :return: Array of bids.\n",
        "    \"\"\"\n",
        "    bids = []\n",
        "    for _ in range(n):\n",
        "        a_k = np.random.choice([0, 1], size=m)  # Generate a_k\n",
        "        pi_k = np.dot(p_bar, a_k) + np.random.normal(0, np.sqrt(0.2))  # Calculate bid price\n",
        "        bids.append((a_k, pi_k))\n",
        "    return bids\n",
        "\n",
        "def solve_offline_lp(bids, m, b_i):\n",
        "    c = -np.array([pi_k for _, pi_k in bids])  # Negative for maximization\n",
        "    A = np.array([a_k for a_k, _ in bids]).T  # Transpose to match dimensions\n",
        "    b = b_i * np.ones(m)\n",
        "\n",
        "    # Solving the LP\n",
        "    result = linprog(c, A_ub=A, b_ub=b, bounds=(0, 1), method='highs')\n",
        "\n",
        "    if result.success:\n",
        "        return -result.fun  # Revenue (negate because of maximization)\n",
        "    else:\n",
        "        raise ValueError(\"Offline LP did not converge\")\n",
        "\n",
        "def solve_partial_lp_dual(bids, k, n, b_i):\n",
        "    # Objective function: maximize sum(pi_j * x_j) for j=1 to k\n",
        "    c = -np.array([pi_k for _, pi_k in bids[:k]])\n",
        "\n",
        "    # Constraints: sum(a_ij * x_j) <= (k/n) * b_i for all i\n",
        "    A = np.array([a_k for a_k, _ in bids[:k]]).T\n",
        "    b = (k / n) * np.array(b_i)\n",
        "\n",
        "    # Bounds for decision variables: 0 <= x_j <= 1\n",
        "    x_bounds = [(0, 1) for _ in range(k)]\n",
        "\n",
        "    # Solve the linear program\n",
        "    result = linprog(c, A_ub=A, b_ub=b, bounds=x_bounds, method='highs')\n",
        "\n",
        "    # print(result.ineqlin.get('marginals'))\n",
        "\n",
        "    if result.success:\n",
        "        # The dual variable corresponding to the inequality constraints A_ub * x <= b_ub\n",
        "        return result.get('slack'), -1*result.ineqlin.get('marginals'), result.get('fun')\n",
        "    else:\n",
        "        raise ValueError(\"failed to find a solution\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_dplm = []\n",
        "diff_ahdla = []\n",
        "revenues = {}\n",
        "\n",
        "n = 10000  # Total number of bids\n",
        "m = 10     # Number of items\n",
        "b_i = np.ones(m) * 1000  # Bid cap for all i\n",
        "# Fixed ground truth price vector (p_bar) - set to ones for simplicity\n",
        "p_bar = np.ones(m)  # Vector of ones\n",
        "k_values = [50, 100, 200]  # Different k values to test\n",
        "# Regenerate bids with the fixed p_bar\n",
        "bids_fixed = generate_bids(n, m, p_bar)\n",
        "\n",
        "# offline\n",
        "offline_revenue_value = solve_offline_lp(bids_fixed, m, b_i)\n",
        "print(f\"Offline revenue: {offline_revenue_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6blivPuUqqF",
        "outputId": "a9a5ee1c-4ea4-419a-95b4-2ced6e64fd64"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Offline revenue: 11295.824597861341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1\n",
        "def run_slpm_static(bids, k, n, b_i):\n",
        "    revenue = 0\n",
        "    remaining_capacity = np.array(b_i)\n",
        "    # Solve the partial LP for the first k bids to get dual prices\n",
        "    slack, dual_price, k_revenue = solve_partial_lp_dual(bids, k, n, b_i)\n",
        "    # revenue += -k_revenue\n",
        "    # remaining_capacity = np.array(b_i-((k/n)*b_i-slack))\n",
        "\n",
        "    for i, (a_k, pi_k) in enumerate(bids):\n",
        "        if i >= k:\n",
        "            # Allocate based on the decision rule using y_bar\n",
        "            if pi_k > np.dot(a_k, dual_price) and all(remaining_capacity - a_k >= 0):\n",
        "                revenue += pi_k\n",
        "                remaining_capacity -= a_k\n",
        "\n",
        "    return revenue\n",
        "\n",
        "for k in k_values:\n",
        "    revenue = run_slpm_static(bids_fixed, k, n, b_i)\n",
        "    revenues[k] = revenue\n",
        "\n",
        "for slpm_revenue, k in zip(revenues.values(), k_values):\n",
        "    print(f\"SLPM Static revenue: {slpm_revenue} at k={k}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFr4T2zRUtqP",
        "outputId": "c96f823a-2644-452f-9f9b-e428bf6e19a4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLPM Static revenue: 8704.104241903948 at k=50\n",
            "SLPM Static revenue: 9034.464855685475 at k=100\n",
            "SLPM Static revenue: 10359.845241415733 at k=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The increase in revenue as k grows suggests that having more bidder information upfront (i.e., a larger k) allows the algorithm to make more informed decisions which result in higher revenue.\n",
        "\n",
        "It may have two tradeoffs here, one is tradeoff between cost of computation and accuracy, since with a large k we will need more compuration resources. Another tradeoff is that a larger k implies a delay in decision-making since more bids must be collected before making allocations, which could be a trade-off in real-time scenarios.\n"
      ],
      "metadata": {
        "id": "Rr6idxluV1So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2\n",
        "def run_slpm_dynamic(bids, k, n, b_i, offline_revenue_value):\n",
        "    global diff_dplm\n",
        "    revenue = 0\n",
        "    remaining_capacity = np.array(b_i)\n",
        "\n",
        "    # Solve the partial LP for the first k bids to get dual prices\n",
        "    slack, dual_price, k_revenue = solve_partial_lp_dual(bids, k, n, b_i)\n",
        "    # revenue += -k_revenue\n",
        "    # remaining_capacity = np.array(b_i-((k/n)*b_i-slack))\n",
        "\n",
        "    target = 2*k\n",
        "\n",
        "    for i, (a_k, pi_k) in enumerate(bids):\n",
        "        if i >= k:\n",
        "            if i == target:\n",
        "                slack, dual_price, _ = solve_partial_lp_dual(bids, target, n, b_i)\n",
        "                print(dual_price)\n",
        "                target *= 2\n",
        "            # Allocate based on the decision rule using y_bar\n",
        "            if pi_k > np.dot(a_k, dual_price) and all(remaining_capacity - a_k >= 0):\n",
        "                revenue += pi_k\n",
        "                remaining_capacity -= a_k\n",
        "            diff_dplm.append(revenue-((i+1)/n)*offline_revenue_value)\n",
        "\n",
        "\n",
        "    return revenue\n",
        "\n",
        "revenue = run_slpm_dynamic(bids_fixed, 50, n, b_i, offline_revenue_value)\n",
        "print(f\"SLPM Dynamic revenue: {revenue}\")\n",
        "print(diff_dplm[-20:]) # print first 20 results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nclcty1tUwj8",
        "outputId": "715c24cf-dbe9-4e80-97eb-26ffc3bce328"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6910947  1.27843893 1.0940666  1.02223777 0.9462198  1.05305249\n",
            " 0.79061086 1.13342619 1.24225992 1.28518051]\n",
            "[0.98926579 1.12006768 1.10855944 1.0228186  0.93831595 1.1271953\n",
            " 0.88544887 1.08839671 0.99702215 1.13879167]\n",
            "[1.03064564 1.11848375 1.02024087 1.10948981 0.99559667 1.02561255\n",
            " 0.98869853 1.10638004 1.04024645 1.07308808]\n",
            "[1.07076896 1.1426658  1.05877735 1.05167663 1.00153519 1.13526058\n",
            " 1.07660178 1.06423735 1.00509076 1.02125323]\n",
            "[1.03931965 1.11345259 1.07279337 1.03708435 1.05728996 1.13091132\n",
            " 1.05154387 1.092419   1.01462012 1.04019477]\n",
            "[1.05070048 1.10916328 1.07694991 1.04712715 1.0605825  1.11261206\n",
            " 1.0776834  1.04426491 1.05095298 1.04407662]\n",
            "[1.04956867 1.09277148 1.10910989 1.07651082 1.04161595 1.08685437\n",
            " 1.06723273 1.04268705 1.04802063 1.07022546]\n",
            "SLPM Dynamic revenue: 11030.173656259723\n",
            "[-244.188874865682, -245.31845732546753, -246.44803978525306, -247.57762224503858, -248.70720470482593, -249.83678716461327, -250.9663696243988, -252.09595208418432, -253.22553454396984, -254.3551170037572, -255.4846994635427, -256.61428192332824, -257.74386438311376, -258.8734468429011, -260.00302930268845, -261.13261176247397, -262.2621942222595, -263.391776682045, -264.52135914183236, -265.6509416016179]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this question, instead of using a fixed dual price, we update our dual price on k= [50, 100, 200, 400, 800, ...], and using this stratege, we can get better performance than with fixed dual price, 10905.843288804756 compare to revenue in question above.\n",
        "\n",
        "Also we print all dual price on each update time point. As we can see, it approches to the ground true price p = [1,1,...,1,1] we set before."
      ],
      "metadata": {
        "id": "QFAHdmSyWJpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3\n",
        "def run_ahdla(bids, k, n, b_i, offline_revenue_value):\n",
        "    global diff_ahdla\n",
        "    batch = 50\n",
        "    revenue = 0\n",
        "    dual_price = np.zeros(m)\n",
        "    remaining_capacity = b_i\n",
        "    target = batch*k\n",
        "\n",
        "    for i, (a_k, pi_k) in enumerate(bids):\n",
        "        # Allocate based on the decision rule using y_bar\n",
        "        if pi_k > np.dot(a_k, dual_price) and all(remaining_capacity - a_k >= 0):\n",
        "            revenue += pi_k\n",
        "            remaining_capacity -= a_k\n",
        "        diff_ahdla.append(revenue-((i+1)/n)*offline_revenue_value)\n",
        "        if i == target and i < n-1:\n",
        "            _, dual_price, _ = solve_partial_lp_dual(bids, i+1, n, (n/(n-i-1))*remaining_capacity)\n",
        "            target += batch\n",
        "\n",
        "    return revenue\n",
        "\n",
        "revenue = run_ahdla(bids_fixed, 1, n, b_i, offline_revenue_value)\n",
        "print(f\"Action-history-dependent Learning Algorithm revenue: {revenue}\")\n",
        "print(diff_ahdla[-20:]) # print first 20 results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CowYaNqZUx77",
        "outputId": "04ec3fd1-319d-4c7e-81bf-8a0fe1a1192f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action-history-dependent Learning Algorithm revenue: 11236.862071318921\n",
            "[-49.364971743409114, -50.49455420319464, -51.62413666298016, -52.75371912276569, -53.88330158255303, -55.012884042340374, -56.1424665021259, -52.160221494828875, -53.2898039546144, -54.41938641440174, -55.54896887418727, -56.67855133397279, -57.808133793758316, -52.18503178370338, -53.31461424349072, -54.44419670327625, -55.57377916306177, -56.7033616228473, -57.83294408263464, -58.962526542420164]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Action-history-dependent Learning Algorithm, instead of updating dual price in a frequency of [50, 100, 200, ...], we update it for each batch, we set 50 here. And as we can see, the revenue is higher than what we got from problem 2.\n",
        "\n",
        "Hence Action-history-dependent Learning Algorithm have better performance. Becuase it also update with remaining capacity information.\n",
        "\n",
        "As we can see in the difference vector, compared with problem 2, (see result on problem2), Action-history-dependent Learning Algorithm is closer to partial of optimal solution at each time point."
      ],
      "metadata": {
        "id": "rTKOukdmWp50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4\n",
        "## Convexity\n",
        "\n",
        "The Formulation (3) in question is as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{minimize}_{\\bar{\\mathbf{y}}} \\; & \\;\\mathbf{d}^T \\bar{\\mathbf{y}} + \\mathbb{E}\\left(\\pi - \\mathbf{a}^T \\bar{\\mathbf{y}}\\right)^+ \\\\\n",
        "\\text{s.t. } & \\bar{\\mathbf{y}} \\geq 0\n",
        "\\end{align*}\n",
        "\n",
        "where $\\mathbf{d} = \\frac{\\mathbf{b}}{n}$ and $(\\cdot)^+ = \\max \\{\\cdot, 0\\}$.\n",
        "\n",
        "To identify whether (3) is a convex optimization problem or not, we can analyze each part of (3) separately.\n",
        "\n",
        "For the first part $\\mathbf{d}^T \\bar{\\mathbf{y}}$ of (3), $\\mathbf{d}^T \\bar{\\mathbf{y}}$ is liner in $\\bar{\\mathbf{y}}$. We know that linear functions are both convex and concave.\n",
        "\n",
        "For the second part $\\mathbb{E}\\left(\\pi - \\mathbf{a}^T \\bar{\\mathbf{y}}\\right)^+$, since $\\pi - \\mathbf{a}^T \\bar{\\mathbf{y}}$ is linear in $\\bar{\\mathbf{y}}$. What $(\\cdot)^+$ does is to get maximum value between this linear function and zero, since both of them are convex, $\\left(\\pi - \\mathbf{a}^T \\bar{\\mathbf{y}}\\right)^+$ is also convex. The last part we need to consider is the expectation. From Jensen's inequality:\n",
        "\n",
        "$$\\mathbb{E}[f(X)]â‰¥f(\\mathbb{E}[X])$$\n",
        "\n",
        "we know that if $f(x)$ is convex, then $\\mathbb{E}[f(x)]$ is also convex. Therefore, $\\mathbb{E}\\left(\\pi - \\mathbf{a}^T \\bar{\\mathbf{y}}\\right)^+$ is convex.\n",
        "\n",
        "Since both parts of (3) are convex, we know that (3) is a convex optimization problem.\n",
        "\n",
        "## Connection\n",
        "\n",
        "The dual problem of (1) is:\n",
        "\n",
        "$$\n",
        "\\min \\sum_{i=1}^{m} b_iy_i + \\sum_{j=1}^{n} \\beta_j\\\\\n",
        "\\text{s.t.} \\sum_{i=1}^{m} a_{ij}y_i + \\beta_j \\geq \\pi_j, \\quad j=1,\\ldots,n.\\\\\n",
        "y_i, \\beta_j \\geq 0 \\text{ for all } i, j\n",
        "$$\n",
        "\n",
        "From previous questions, we know that the primal optimal solution satisfies:\n",
        "$$\n",
        "x_j^* =\n",
        "\\begin{cases}\n",
        "1, & \\text{if } \\pi_j > a_j^T y_k^* \\\\\n",
        "0, & \\text{if } \\pi_j \\leq a_j^T y_k^*.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "the optimal solution $x_j$ may take non-integer values. That means the optimal solution of primary problem (1) highly depends on $y$. So by plugging the constraints $\\sum_{i=1}^{m} a_{ij}y_i + \\beta_j \\geq \\pi_j$ into the objective function, an equivalent form of the dual problem can be obtained as:\n",
        "$$\n",
        "\\min \\sum_{i=1}^{m} b_i y_i + \\sum_{j=1}^{n} \\left( \\pi_j - \\sum_{i=1}^{m} a_{ij} y_i \\right)^+\\\\\n",
        "\\text{s.t. } y_i \\geq 0, \\quad i = 1, \\ldots, m.\n",
        "$$\n",
        "\n",
        "And if we devide it by $n$, from above we know that $\\mathbf{d} = \\frac{\\mathbf{b}}{n}$, so we now have:\n",
        "$$\n",
        "\\min f_n(\\bar{\\mathbf{y}}) = \\sum_{i=1}^{m} d_i y_i + \\frac{1}{n} \\sum_{j=1}^{n} \\left( \\pi_j - \\sum_{i=1}^{m} a_{ij} y_i \\right)^+\\\\\n",
        "\\text{s.t. } y_i \\geq 0, \\quad i = 1, \\ldots, m.\n",
        "$$\n",
        "\n",
        "Since $(\\pi, a)$ is a sequence of i.i.d. random vectors, we can also write this formulation as:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\text{minimize}_{\\bar{\\mathbf{y}}} \\; & \\;\\mathbf{d}^T \\bar{\\mathbf{y}} + \\mathbb{E}\\left(\\pi - \\mathbf{a}^T \\bar{\\mathbf{y}}\\right)^+ \\\\\n",
        "\\text{s.t. } & \\bar{\\mathbf{y}} \\geq 0\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where the expectation is taken with respect to $(\\pi, a)$.\n"
      ],
      "metadata": {
        "id": "RCFy7qPn5jQg"
      }
    }
  ]
}